# 深度学习

##### 神经网络中的Epoch，Iteration，Batchsize

神经网络中epoch与iteration是不相等的

- **batchsize**：中文译为 批大小(批尺寸)。在深度学习中，一般采用SGD训练，即每次训练在训练集中取 batchsize 个样本训练；
- **iteration**:  中文翻译为迭代，1个iteration等于使用batchsize个样本训练一次；一个迭代 = 一个正向通过 + 一个反向通过
- **epoch**: 迭代次数，1个epoch等于使用训练集中的全部样本训练一次；一个epoch = 所有训练样本的一个正向传递 + 一个反向传递

举个例子，训练集有1000个样本，batchsize=10，那么：训练完整个样本集需要：100次iteration，1次epoch。

##### 反向传播（BP）

 

